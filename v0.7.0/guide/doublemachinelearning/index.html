<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Double Machine Learning · CausalELM</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://dscolby.github.io/CausalELM.jl/guide/doublemachinelearning/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.jpg" alt="CausalELM logo"/></a><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">CausalELM</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../estimatorselection/">Deciding Which Estimator to Use</a></li><li><a class="tocitem" href="../its/">Interrupted Time Series Estimation</a></li><li><a class="tocitem" href="../gcomputation/">G-computation</a></li><li class="is-active"><a class="tocitem" href>Double Machine Learning</a><ul class="internal"><li><a class="tocitem" href="#Step-1:-Initialize-a-Model"><span>Step 1: Initialize a Model</span></a></li><li><a class="tocitem" href="#Step-2:-Estimate-the-Causal-Effect"><span>Step 2: Estimate the Causal Effect</span></a></li><li class="toplevel"><a class="tocitem" href="#Get-a-Summary"><span>Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model"><span>Step 4: Validate the Model</span></a></li></ul></li><li><a class="tocitem" href="../metalearners/">Metalearners</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Getting Started</a></li><li class="is-active"><a href>Double Machine Learning</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Double Machine Learning</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dscolby/CausalELM.jl/blob/main/docs/src/guide/doublemachinelearning.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Double-Machine-Learning"><a class="docs-heading-anchor" href="#Double-Machine-Learning">Double Machine Learning</a><a id="Double-Machine-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Double-Machine-Learning" title="Permalink"></a></h1><p>Double machine learning, also called debiased or orthogonalized machine learning, enables estimating causal effects when the dimensionality of the covariates is too high for linear  regression or the treatment or outcomes cannot be easily modeled parametrically. Double  machine learning estimates models of the treatment assignment and outcome and then combines  them in a final model. This is a semiparametric model in the sense that the first stage  models can take on any functional form but the final stage model is a linear combination of  the residuals from the first stage models.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For more information see:</p><p>Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen,  Whitney Newey, and James Robins. &quot;Double/debiased machine learning for treatment and  structural parameters.&quot; (2018): C1-C68.</p></div></div><h2 id="Step-1:-Initialize-a-Model"><a class="docs-heading-anchor" href="#Step-1:-Initialize-a-Model">Step 1: Initialize a Model</a><a id="Step-1:-Initialize-a-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Initialize-a-Model" title="Permalink"></a></h2><p>The DoubleMachineLearning constructor takes at least three arguments—covariates, a  treatment statuses, and outcomes, all of which may be either an array or any struct that  implements the Tables.jl interface (e.g. DataFrames). This estimator supports binary, count,  or continuous treatments and binary, count, continuous, or time to event outcomes.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Non-binary categorical outcomes are treated as continuous.</p></div></div><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>You can also specify the the number of folds to use for cross-fitting, the number of  extreme learning machines to incorporate in the ensemble, the number of features to  consider for each extreme learning machine, the activation function to use, the number  of observations to bootstrap in each extreme learning machine, and the number of neurons  in each extreme learning machine. These arguments are specified with the folds,  num<em>machines, num</em>features, activation, sample<em>size, and num\</em>neurons keywords.</p></div></div><pre><code class="language-julia hljs"># Create some data with a binary treatment
X, T, Y, W = rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100), rand(100, 4)

# We could also use DataFrames or any other package implementing the Tables.jl API
# using DataFrames
# X = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100), x5=rand(100))
# T, Y = DataFrame(t=[rand()&lt;0.4 for i in 1:100]), DataFrame(y=rand(100))
dml = DoubleMachineLearning(X, T, Y)</code></pre><h2 id="Step-2:-Estimate-the-Causal-Effect"><a class="docs-heading-anchor" href="#Step-2:-Estimate-the-Causal-Effect">Step 2: Estimate the Causal Effect</a><a id="Step-2:-Estimate-the-Causal-Effect-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Estimate-the-Causal-Effect" title="Permalink"></a></h2><p>To estimate the causal effect, we call estimate<em>causal</em>effect! on the model above.</p><pre><code class="language-julia hljs"># we could also estimate the ATT by passing quantity_of_interest=&quot;ATT&quot;
estimate_causal_effect!(dml)</code></pre><h1 id="Get-a-Summary"><a class="docs-heading-anchor" href="#Get-a-Summary">Get a Summary</a><a id="Get-a-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Get-a-Summary" title="Permalink"></a></h1><p>We can get a summary of the model by pasing the model to the summarize method.</p><p>!!!note     To calculate the p-value and standard error for the treatmetn effect, you can set the      inference argument to false. However, p-values and standard errors are calculated via      randomization inference, which will take a long time. But can be sped up by launching      Julia with a higher number of threads.</p><pre><code class="language-julia hljs"># Can also use the British spelling
# summarise(dml)
summarize(dml)</code></pre><h2 id="Step-4:-Validate-the-Model"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model">Step 4: Validate the Model</a><a id="Step-4:-Validate-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model" title="Permalink"></a></h2><p>We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we simulate counterfactual outcomes that are  different from the observed outcomes, estimate models with the simulated counterfactual  outcomes, and take the averages. If the outcome is continuous, the noise for the simulated  counterfactuals is drawn from N(0, dev) for each element in devs and each outcome,  multiplied by the original outcome, and added to the original outcome. For discrete  variables, each outcome is replaced with a different value in the range of outcomes with  probability ϵ for each ϵ in devs, otherwise the default is 0.025, 0.05, 0.075, 0.1. If the  average estimate for a given level of violation differs greatly from the effect estimated on  the actual data, then the model is very sensitive to violations of the counterfactual  consistency assumption for that level of violation. Next, this method tests the model&#39;s  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  or near zero probability of treatment. If the matrix is empty, none of the observations have  an estimated zero probability of treatment, which implies the positivity assumption is  satisfied.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>One can also specify the maxium number of possible treatments to consider for the causal  consistency assumption and the minimum and maximum probabilities of treatment for the  positivity assumption with the num_treatments, min, and max keyword arguments.</p></div></div><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>Obtaining correct estimates is dependent on meeting the assumptions for double machine  learning. If the assumptions are not met then any estimates may be biased and lead to  incorrect conclusions.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a thorough review of casual inference assumptions see:</p><pre><code class="nohighlight hljs">Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and 
Francis, 2024.</code></pre><p>For more information on the E-value test see:</p><pre><code class="nohighlight hljs">VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research: 
introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</code></pre></div></div><pre><code class="language-julia hljs">validate(g_computer)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gcomputation/">« G-computation</a><a class="docs-footer-nextpage" href="../metalearners/">Metalearners »</a><div class="flexbox-break"></div><p class="footer-message">© 2024 Darren Colby</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Saturday 6 July 2024 00:40">Saturday 6 July 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
