<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · CausalELM</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://dscolby.github.io/CausalELM.jl/api/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.jpg" alt="CausalELM logo"/></a><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">CausalELM</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../guide/estimatorselection/">Deciding Which Estimator to Use</a></li><li><a class="tocitem" href="../guide/its/">Interrupted Time Series Estimation</a></li><li><a class="tocitem" href="../guide/gcomputation/">G-computation</a></li><li><a class="tocitem" href="../guide/doublemachinelearning/">Double Machine Learning</a></li><li><a class="tocitem" href="../guide/metalearners/">Metalearners</a></li></ul></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#Types"><span>Types</span></a></li><li><a class="tocitem" href="#Activation-Functions"><span>Activation Functions</span></a></li><li><a class="tocitem" href="#Average-Causal-Effect-Estimators"><span>Average Causal Effect Estimators</span></a></li><li><a class="tocitem" href="#Metalearners"><span>Metalearners</span></a></li><li><a class="tocitem" href="#Common-Methods"><span>Common Methods</span></a></li><li><a class="tocitem" href="#Inference"><span>Inference</span></a></li><li><a class="tocitem" href="#Model-Validation"><span>Model Validation</span></a></li><li><a class="tocitem" href="#Validation-Metrics"><span>Validation Metrics</span></a></li><li><a class="tocitem" href="#Extreme-Learning-Machines"><span>Extreme Learning Machines</span></a></li><li><a class="tocitem" href="#Utility-Functions"><span>Utility Functions</span></a></li></ul></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dscolby/CausalELM.jl/blob/main/docs/src/api.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="CausalELM"><a class="docs-heading-anchor" href="#CausalELM">CausalELM</a><a id="CausalELM-1"></a><a class="docs-heading-anchor-permalink" href="#CausalELM" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="CausalELM.CausalELM" href="#CausalELM.CausalELM"><code>CausalELM.CausalELM</code></a> — <span class="docstring-category">Module</span></header><section><div><p>Macros, functions, and structs for applying Ensembles of extreme learning machines to causal  inference tasks where the counterfactual is unavailable or biased and must be predicted.  Supports causal inference via interrupted time series designs, parametric G-computation,  double machine learning, and S-learning, T-learning, X-learning, R-learning, and doubly  robust estimation.</p><p>For more details on Extreme Learning Machines see:     Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. &quot;Extreme learning machine: theory      and applications.&quot; Neurocomputing 70, no. 1-3 (2006): 489-501.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/CausalELM.jl#L1-L11">source</a></section></article><h2 id="Types"><a class="docs-heading-anchor" href="#Types">Types</a><a id="Types-1"></a><a class="docs-heading-anchor-permalink" href="#Types" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.InterruptedTimeSeries" href="#CausalELM.InterruptedTimeSeries"><code>CausalELM.InterruptedTimeSeries</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">InterruptedTimeSeries(X₀, Y₀, X₁, Y₁; kwargs...)</code></pre><p>Initialize an interrupted time series estimator. </p><p><strong>Arguments</strong></p><ul><li><code>X₀::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates from the    pre-treatment period.</li><li><code>Y₁::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes from the    pre-treatment period.</li><li><code>X₁::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates from the    post-treatment period.</li><li><code>Y₁::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes from the    post-treatment period.</li></ul><p><strong>Keywords</strong></p><ul><li><code>activation::Function=swish</code>: activation function to use.</li><li><code>sample_size::Integer=size(X₀, 1)</code>: number of bootstrapped samples for the extreme    learner.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75 * size(X₀, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For a simple linear regression-based tutorial on interrupted time series analysis see:     Bernal, James Lopez, Steven Cummins, and Antonio Gasparrini. &quot;Interrupted time series      regression for the evaluation of public health interventions: a tutorial.&quot; International      journal of epidemiology 46, no. 1 (2017): 348-355.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X₀, Y₀, X₁, Y₁ =  rand(100, 5), rand(100), rand(10, 5), rand(10)
julia&gt; m1 = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)
julia&gt; m2 = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁; regularized=false)
julia&gt; x₀_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100))
julia&gt; y₀_df = DataFrame(y=rand(100))
julia&gt; x₁_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100)) 
julia&gt; y₁_df = DataFrame(y=rand(100))
julia&gt; m3 = InterruptedTimeSeries(x₀_df, y₀_df, x₁_df, y₁_df)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L4-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.GComputation" href="#CausalELM.GComputation"><code>CausalELM.GComputation</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">GComputation(X, T, Y; kwargs...)</code></pre><p>Initialize a G-Computation estimator.</p><p><strong>Arguments</strong></p><ul><li><code>X::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates.</li><li><code>T::Any</code>: AbstractArray or Tables.jl API compliant data structure of treatment statuses.</li><li><code>Y::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes.</li></ul><p><strong>Keywords</strong></p><ul><li><code>quantity_of_interest::String</code>: ATE for average treatment effect or ATT for average    treatment effect on the treated.</li><li><code>activation::Function=swish</code>: activation function to use.</li><li><code>sample_size::Integer=size(X, 1)</code>: number of bootstrapped samples for the extreme    learners.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75 * size(X, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For a good overview of G-Computation see:     Chatton, Arthur, Florent Le Borgne, Clémence Leyrat, Florence Gillaizeau, Chloé      Rousseau, Laetitia Barbin, David Laplaud, Maxime Léger, Bruno Giraudeau, and Yohann      Foucher. &quot;G-computation, propensity score-based methods, and targeted maximum likelihood      estimator for causal inference with different covariates sets: a comparative simulation      study.&quot; Scientific reports 10, no. 1 (2020): 9219.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), rand(100), [rand()&lt;0.4 for i in 1:100]
julia&gt; m1 = GComputation(X, T, Y)
julia&gt; m2 = GComputation(X, T, Y; task=&quot;regression&quot;)
julia&gt; m3 = GComputation(X, T, Y; task=&quot;regression&quot;, quantity_of_interest=&quot;ATE)

julia&gt; x_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100))
julia&gt; t_df, y_df = DataFrame(t=rand(0:1, 100)), DataFrame(y=rand(100)) 
julia&gt; m5 = GComputation(x_df, t_df, y_df)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L98-L142">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.DoubleMachineLearning" href="#CausalELM.DoubleMachineLearning"><code>CausalELM.DoubleMachineLearning</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DoubleMachineLearning(X, T, Y; kwargs...)</code></pre><p>Initialize a double machine learning estimator with cross fitting.</p><p><strong>Arguments</strong></p><ul><li><code>X::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates of   interest.</li><li><code>T::Any</code>: AbstractArray or Tables.jl API compliant data structure of treatment statuses.</li><li><code>Y::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes.</li></ul><p><strong>Keywords</strong></p><ul><li><code>activation::Function=swish</code>: activation function to use.</li><li><code>sample_size::Integer=size(X, 1)</code>: number of bootstrapped samples for teh extreme    learners.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75, * size(X, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li><li><code>folds::Integer</code>: number of folds to use for cross fitting.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For more information see:     Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen,      Whitney Newey, and James Robins. &quot;Double/debiased machine learning for treatment and      structural parameters.&quot; (2016): C1-C68.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = DoubleMachineLearning(X, T, Y)

julia&gt; x_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100))
julia&gt; t_df, y_df = DataFrame(t=rand(0:1, 100)), DataFrame(y=rand(100))
julia&gt; m2 = DoubleMachineLearning(x_df, t_df, y_df)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L188-L228">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.SLearner" href="#CausalELM.SLearner"><code>CausalELM.SLearner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">SLearner(X, T, Y; kwargs...)</code></pre><p>Initialize a S-Learner.</p><p><strong>Arguments</strong></p><ul><li><code>X::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates.</li><li><code>T::Any</code>: AbstractArray or Tables.jl API compliant data structure of treatment statuses.</li><li><code>Y::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes.</li></ul><p><strong>Keywords</strong></p><ul><li><code>activation::Function=swish</code>: the activation function to use.</li><li><code>sample_size::Integer=size(X, 1)</code>: number of bootstrapped samples for eth extreme    learners.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75 * size(X, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For an overview of S-Learners and other metalearners see:     Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for      estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of      the national academy of sciences 116, no. 10 (2019): 4156-4165.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = SLearner(X, T, Y)
julia&gt; m2 = SLearner(X, T, Y; task=&quot;regression&quot;)
julia&gt; m3 = SLearner(X, T, Y; task=&quot;regression&quot;, regularized=true)

julia&gt; x_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100))
julia&gt; t_df, y_df = DataFrame(t=rand(0:1, 100)), DataFrame(y=rand(100))
julia&gt; m4 = SLearner(x_df, t_df, y_df)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L4-L44">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.TLearner" href="#CausalELM.TLearner"><code>CausalELM.TLearner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TLearner(X, T, Y; kwargs...)</code></pre><p>Initialize a T-Learner.</p><p><strong>Arguments</strong></p><ul><li><code>X::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates.</li><li><code>T::Any</code>: AbstractArray or Tables.jl API compliant data structure of treatment statuses.</li><li><code>Y::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes.</li></ul><p><strong>Keywords</strong></p><ul><li><code>activation::Function=swish</code>: the activation function to use.</li><li><code>sample_size::Integer=size(X, 1)</code>: number of bootstrapped samples for eth extreme    learners.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75 * size(X, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For an overview of T-Learners and other metalearners see:     Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for      estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of      the national academy of sciences 116, no. 10 (2019): 4156-4165.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = TLearner(X, T, Y)
julia&gt; m2 = TLearner(X, T, Y; regularized=false)

julia&gt; x_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100))
julia&gt; t_df, y_df = DataFrame(t=rand(0:1, 100)), DataFrame(y=rand(100))
julia&gt; m3 = TLearner(x_df, t_df, y_df)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L85-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.XLearner" href="#CausalELM.XLearner"><code>CausalELM.XLearner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">XLearner(X, T, Y; kwargs...)</code></pre><p>Initialize an X-Learner.</p><p><strong>Arguments</strong></p><ul><li><code>X::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates.</li><li><code>T::Any</code>: AbstractArray or Tables.jl API compliant data structure of treatment statuses.</li><li><code>Y::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes.</li></ul><p><strong>Keywords</strong></p><ul><li><code>activation::Function=swish</code>: the activation function to use.</li><li><code>sample_size::Integer=size(X, 1)</code>: number of bootstrapped samples for eth extreme    learners.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75 * size(X, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For an overview of X-Learners and other metalearners see:     Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for      estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of the      national academy of sciences 116, no. 10 (2019): 4156-4165.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = XLearner(X, T, Y)
julia&gt; m2 = XLearner(X, T, Y; regularized=false)

julia&gt; x_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100))
julia&gt; t_df, y_df = DataFrame(t=rand(0:1, 100)), DataFrame(y=rand(100))
julia&gt; m3 = XLearner(x_df, t_df, y_df)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L165-L204">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.RLearner" href="#CausalELM.RLearner"><code>CausalELM.RLearner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RLearner(X, T, Y; kwargs...)</code></pre><p>Initialize an R-Learner.</p><p><strong>Arguments</strong></p><ul><li><code>X::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates of    interest.</li><li><code>T::Any</code>: AbstractArray or Tables.jl API compliant data structure of treatment statuses.</li><li><code>Y::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes.</li></ul><p><strong>Keywords</strong></p><ul><li><code>activation::Function=swish</code>: the activation function to use.</li><li><code>sample_size::Integer=size(X, 1)</code>: number of bootstrapped samples for eth extreme    learners.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75 * size(X, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For an explanation of R-Learner estimation see:     Nie, Xinkun, and Stefan Wager. &quot;Quasi-oracle estimation of heterogeneous treatment      effects.&quot; Biometrika 108, no. 2 (2021): 299-319.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = RLearner(X, T, Y)

julia&gt; x_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100))
julia&gt; t_df, y_df = DataFrame(t=rand(0:1, 100)), DataFrame(y=rand(100))
julia&gt; m2 = RLearner(x_df, t_df, y_df)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L246-L284">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.DoublyRobustLearner" href="#CausalELM.DoublyRobustLearner"><code>CausalELM.DoublyRobustLearner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DoublyRobustLearner(X, T, Y; kwargs...)</code></pre><p>Initialize a doubly robust CATE estimator.</p><p><strong>Arguments</strong></p><ul><li><code>X::Any</code>: AbstractArray or Tables.jl API compliant data structure of covariates of    interest.</li><li><code>T::Any</code>: AbstractArray or Tables.jl API compliant data structure of treatment statuses.</li><li><code>Y::Any</code>: AbstractArray or Tables.jl API compliant data structure of outcomes.</li></ul><p><strong>Keywords</strong></p><ul><li><code>activation::Function=swish</code>: the activation function to use.</li><li><code>sample_size::Integer=size(X, 1)</code>: number of bootstrapped samples for eth extreme    learners.</li><li><code>num_machines::Integer=50</code>: number of extreme learning machines for the ensemble.</li><li><code>num_feats::Integer=Int(round(0.75 * size(X, 2)))</code>: number of features to bootstrap for    each learner in the ensemble.</li><li><code>num_neurons::Integer</code>: number of neurons to use in the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>To reduce the computational complexity you can reduce sample<em>size, num</em>machines, or  num_neurons.</p><p><strong>References</strong></p><p>For an explanation of doubly robust cate estimation see:     Kennedy, Edward H. &quot;Towards optimal doubly robust estimation of heterogeneous causal      effects.&quot; Electronic Journal of Statistics 17, no. 2 (2023): 3008-3049.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = DoublyRobustLearner(X, T, Y)

julia&gt; x_df = DataFrame(x1=rand(100), x2=rand(100), x3=rand(100), x4=rand(100))
julia&gt; t_df, y_df = DataFrame(t=rand(0:1, 100)), DataFrame(y=rand(100))
julia&gt; m2 = DoublyRobustLearner(x_df, t_df, y_df)

julia&gt; w = rand(100, 6)
julia&gt; m3 = DoublyRobustLearner(X, T, Y, W=w)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L331-L372">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.CausalEstimator" href="#CausalELM.CausalEstimator"><code>CausalELM.CausalEstimator</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type for GComputation and DoubleMachineLearning</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.Metalearner" href="#CausalELM.Metalearner"><code>CausalELM.Metalearner</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type for metalearners</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L1">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.ExtremeLearner" href="#CausalELM.ExtremeLearner"><code>CausalELM.ExtremeLearner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ExtremeLearner(X, Y, hidden_neurons, activation)</code></pre><p>Construct an ExtremeLearner for fitting and prediction.</p><p><strong>Notes</strong></p><p>While it is possible to use an ExtremeLearner for regression, it is recommended to use  RegularizedExtremeLearner, which imposes an L2 penalty, to reduce multicollinearity.</p><p><strong>References</strong></p><p>For more details see:      Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. &quot;Extreme learning machine: theory      and applications.&quot; Neurocomputing 70, no. 1-3 (2006): 489-501.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, y = [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0], [0.0, 1.0, 0.0, 1.0]
julia&gt; m1 = ExtremeLearner(x, y, 10, σ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L3-L22">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.ELMEnsemble" href="#CausalELM.ELMEnsemble"><code>CausalELM.ELMEnsemble</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ELMEnsemble(X, Y, sample_size, num_machines, num_neurons)</code></pre><p>Initialize a bagging ensemble of extreme learning machines. </p><p><strong>Arguments</strong></p><ul><li><code>X::Array{Float64}</code>: array of features for predicting labels.</li><li><code>Y::Array{Float64}</code>: array of labels to predict.</li><li><code>sample_size::Integer</code>: how many data points to use for each extreme learning machine.</li><li><code>num_machines::Integer</code>: how many extreme learning machines to use.</li><li><code>num_feats::Integer</code>: how many features to consider for eac exreme learning machine.</li><li><code>num_neurons::Integer</code>: how many neurons to use for each extreme learning machine.</li><li><code>activation::Function</code>: activation function to use for the extreme learning machines.</li></ul><p><strong>Notes</strong></p><p>ELMEnsemble uses the same bagging approach as random forests when the labels are continuous  but uses the average predicted probability, rather than voting, for classification.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, Y =  rand(100, 5), rand(100)
julia&gt; m1 = ELMEnsemble(X, Y, 10, 50, 5, 5, CausalELM.relu)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L41-L64">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.Nonbinary" href="#CausalELM.Nonbinary"><code>CausalELM.Nonbinary</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Abstract type used to dispatch risk_ratio on nonbinary treatments</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L4">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.Binary" href="#CausalELM.Binary"><code>CausalELM.Binary</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Type used to dispatch risk_ratio on binary treatments</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.Count" href="#CausalELM.Count"><code>CausalELM.Count</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Type used to dispatch risk_ratio on count treatments</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.Continuous" href="#CausalELM.Continuous"><code>CausalELM.Continuous</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Type used to dispatch risk_ratio on continuous treatments</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L13">source</a></section></article><h2 id="Activation-Functions"><a class="docs-heading-anchor" href="#Activation-Functions">Activation Functions</a><a id="Activation-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Activation-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.binary_step" href="#CausalELM.binary_step"><code>CausalELM.binary_step</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">binary_step(x)</code></pre><p>Apply the binary step activation function.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; binary_step(1)
1

julia&gt; binary_step([-1000, 100, 1, 0, -0.001, -3])
6-element Vector{Int64}:
 0
 1
 1
 1
 0
 0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L1-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.σ" href="#CausalELM.σ"><code>CausalELM.σ</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">σ(x)</code></pre><p>Apply the sigmoid activation function.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; σ(1)
0.7310585786300049

julia&gt; σ([1.0, 0.0])
2-element Vector{Float64}:
 0.7310585786300049
 0.5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L25-L40">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.tanh" href="#CausalELM.tanh"><code>CausalELM.tanh</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">tanh(x)</code></pre><p>Apply the hyperbolic tangent activation function.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.tanh([1.0, 0.0])
2-element Vector{Float64}:
 0.7615941559557649
 0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L48-L60">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.relu" href="#CausalELM.relu"><code>CausalELM.relu</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">relu(x)</code></pre><p>Apply the ReLU activation function.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; relu(1)
1

julia&gt; relu([1.0, 0.0, -1.0])
3-element Vector{Float64}:
 1.0
 0.0
 0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L63-L79">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.leaky_relu" href="#CausalELM.leaky_relu"><code>CausalELM.leaky_relu</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">leaky_relu(x)</code></pre><p>Apply the leaky ReLU activation function to a number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; leaky_relu(1)
1

julia&gt; leaky_relu([-1.0, 0.0, 1.0])
3-element Vector{Float64}:
 -0.01
  0.0
  1.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L84-L100">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.swish" href="#CausalELM.swish"><code>CausalELM.swish</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">swish(x)</code></pre><p>Apply the swish activation function to a number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; swish(1)
0.7310585786300049

julia&gt; swish([1.0, -1.0])
2-element Vector{Float64}:
  0.7310585786300049
 -0.2689414213699951</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L105-L120">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.softmax" href="#CausalELM.softmax"><code>CausalELM.softmax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">softmax(x)</code></pre><p>Apply the softmax activation function to a number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; softmax(1)
1.0

julia&gt; softmax([1.0, 2.0, 3.0])
3-element Vector{Float64}:
 0.09003057317038045
 0.24472847105479764
 0.6652409557748219

julia&gt; softmax([1.0 2.0 3.0; 4.0 5.0 6.0])
2×3 Matrix{Float64}:
 0.0900306  0.244728  0.665241
 0.0900306  0.244728  0.665241</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L125-L146">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.softplus" href="#CausalELM.softplus"><code>CausalELM.softplus</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">softplus(x)</code></pre><p>Apply the softplus activation function to a number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; softplus(1)
1.3132616875182228

julia&gt; softplus([1.0, -1.0])
2-element Vector{Float64}:
 1.3132616875182228
 0.3132616875182228</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L153-L168">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.gelu" href="#CausalELM.gelu"><code>CausalELM.gelu</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">gelu(x)</code></pre><p>Apply the GeLU activation function to a number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; gelu(1)
0.8411919906082768

julia&gt; gelu([-1.0, 0.0])
2-element Vector{Float64}:
 -0.15880800939172324
  0.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L173-L188">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.gaussian" href="#CausalELM.gaussian"><code>CausalELM.gaussian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">gaussian(x)</code></pre><p>Apply the gaussian activation function to a real number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; gaussian(1)
0.36787944117144233

julia&gt; gaussian([1.0, -1.0])
2-element Vector{Float64}:
 0.3678794411714423
 0.3678794411714423</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L193-L208">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.hard_tanh" href="#CausalELM.hard_tanh"><code>CausalELM.hard_tanh</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">hard_tanh(x)</code></pre><p>Apply the hard_tanh activation function to a number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; hard_tanh(-2)
-1

julia&gt; hard_tanh([-2.0, 0.0, 2.0])
3-element Vector{Real}:
 -1
  0.0
  1</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L213-L229">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.elish" href="#CausalELM.elish"><code>CausalELM.elish</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">elish(x)</code></pre><p>Apply the ELiSH activation function to a number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; elish(1)
0.7310585786300049

julia&gt; elish([-1.0, 1.0])
2-element Vector{Float64}:
 -0.17000340156854793
  0.7310585786300049</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L242-L257">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.fourier" href="#CausalELM.fourier"><code>CausalELM.fourier</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">fourrier(x)</code></pre><p>Apply the Fourier activation function to a real number.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; fourier(1)
0.8414709848078965

julia&gt; fourier([-1.0, 1.0])
2-element Vector{Float64}:
 -0.8414709848078965
  0.8414709848078965</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/activation.jl#L262-L277">source</a></section></article><h2 id="Average-Causal-Effect-Estimators"><a class="docs-heading-anchor" href="#Average-Causal-Effect-Estimators">Average Causal Effect Estimators</a><a id="Average-Causal-Effect-Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Average-Causal-Effect-Estimators" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.g_formula!" href="#CausalELM.g_formula!"><code>CausalELM.g_formula!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">g_formula!(g)</code></pre><p>Compute the G-formula for G-computation and S-learning.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = GComputation(X, T, Y)
julia&gt; g_formula!(m1)

julia&gt; m2 = SLearner(X, T, Y)
julia&gt; g_formula!(m2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L330-L344">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.predict_residuals" href="#CausalELM.predict_residuals"><code>CausalELM.predict_residuals</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">predict_residuals(D, x_train, x_test, y_train, y_test, t_train, t_test, Δ)</code></pre><p>Predict treatment, outcome, and marginal effect residuals for double machine learning or  R-learning.</p><p><strong>Notes</strong></p><p>This method should not be called directly.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; x_train, x_test = X[1:80, :], X[81:end, :]
julia&gt; y_train, y_test = Y[1:80], Y[81:end]
julia&gt; t_train, t_test = T[1:80], T[81:100]
julia&gt; m1 = DoubleMachineLearning(X, T, Y)
julia&gt; predict_residuals(m1, x_tr, x_te, y_tr, y_te, t_tr, t_te, zeros(100), 1e-5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L407-L425">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.moving_average" href="#CausalELM.moving_average"><code>CausalELM.moving_average</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">moving_average(x)</code></pre><p>Calculates a cumulative moving average.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; moving_average([1, 2, 3])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L448-L457">source</a></section></article><h2 id="Metalearners"><a class="docs-heading-anchor" href="#Metalearners">Metalearners</a><a id="Metalearners-1"></a><a class="docs-heading-anchor-permalink" href="#Metalearners" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.doubly_robust_formula!" href="#CausalELM.doubly_robust_formula!"><code>CausalELM.doubly_robust_formula!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">doubly_robust_formula!(DRE, X, T, Y)</code></pre><p>Estimate the CATE for a single cross fitting iteration via doubly robust estimation.</p><p><strong>Notes</strong></p><p>This method should not be called directly.</p><p><strong>Arguments</strong></p><ul><li><code>DRE::DoublyRobustLearner</code>: the DoubleMachineLearning struct to estimate the effect for.</li><li><code>X</code>: a vector of three covariate folds.</li><li><code>T</code>: a vector of three treatment folds.</li><li><code>Y</code>: a vector of three outcome folds.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(6, 100)
julia&gt; m1 = DoublyRobustLearner(X, T, Y)
julia&gt; doubly_robust_formula!(m1, X, T, Y)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L618-L638">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.stage1!" href="#CausalELM.stage1!"><code>CausalELM.stage1!</code></a> — <span class="docstring-category">Function</span></header><section><div><p>stage1!(x)</p><p>Estimate the first stage models for an X-learner.</p><p><strong>Notes</strong></p><p>This method should not be called by the user.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = XLearner(X, T, Y)
julia&gt; stage1!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L661-L675">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.stage2!" href="#CausalELM.stage2!"><code>CausalELM.stage2!</code></a> — <span class="docstring-category">Function</span></header><section><div><p>stage2!(x)</p><p>Estimate the second stage models for an X-learner.</p><p><strong>Notes</strong></p><p>This method should not be called by the user.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = XLearner(X, T, Y)
julia&gt; stage1!(m1)
julia&gt; stage2!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L691-L706">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.weight_trick" href="#CausalELM.weight_trick"><code>CausalELM.weight_trick</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">weight_trick(R, T̃, Ỹ)</code></pre><p>Use the weight trick to estimate the causal effect in the final stage of an R-learner.</p><p><strong>Notes</strong></p><p>This method should not be called directly.</p><p><strong>Arguments</strong></p><ul><li><code>R::RLearner</code>: the RLearner struct to estimate the effect for.</li><li><code>T̃</code>: a vector of residuals from predicting the treatment assignment.</li><li><code>Ỹ</code>: a vector of residuals from predicting the outcome.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100), rand(6, 100)
julia&gt; r_learner = RLearner(X, T, Y)
julia&gt; X, T̃, Ỹ = generate_folds(r_learner.X, DRE.T, DRE.Y, DRE.folds)
julia&gt; X_train, X_test = reduce(vcat, X[1:end .!== f]), X[f]
julia&gt; Y_train, Y_test = reduce(vcat, Ỹ[1:end .!== f]), Ỹ[f]
julia&gt; T_train, T_test = reduce(vcat, T̃[1:end .!== f]), T̃[f]
julia&gt; Ỹ[f], T̃[f], _, _ = predict_residuals(
julia&gt;      r_learner, X_train, X_test, Y_train, Y_test, T_train, T_test, Δ
        )
julia&gt; weight_trick(r_learner, T̃, Ỹ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L580-L606">source</a></section></article><h2 id="Common-Methods"><a class="docs-heading-anchor" href="#Common-Methods">Common Methods</a><a id="Common-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Common-Methods" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.estimate_causal_effect!" href="#CausalELM.estimate_causal_effect!"><code>CausalELM.estimate_causal_effect!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">estimate_causal_effect!(its)</code></pre><p>Estimate the effect of an event relative to a predicted counterfactual.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X₀, Y₀, X₁, Y₁ =  rand(100, 5), rand(100), rand(10, 5), rand(10)
julia&gt; m1 = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)
julia&gt; estimate_causal_effect!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L274-L285">source</a></section><section><div><pre><code class="nohighlight hljs">estimate_causal_effect!(g)</code></pre><p>Estimate a causal effect of interest using G-Computation.</p><p><strong>Notes</strong></p><p>If treatents are administered at multiple time periods, the effect will be estimated as the  average difference between the outcome of being treated in all periods and being treated in  no periods. For example, given that ividuals 1, 2, ..., i ∈ I recieved either a treatment  or a placebo in p different periods, the model would estimate the average treatment effect  as E[Yᵢ|T₁=1, T₂=1, ... Tₚ=1, Xₚ] - E[Yᵢ|T₁=0, T₂=0, ... Tₚ=0, Xₚ].</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = GComputation(X, T, Y)
julia&gt; estimate_causal_effect!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L304-L322">source</a></section><section><div><pre><code class="nohighlight hljs">estimate_causal_effect!(DML)</code></pre><p>Estimate a causal effect of interest using double machine learning.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = DoubleMachineLearning(X, T, Y)
julia&gt; estimate_causal_effect!(m1)

julia&gt; W = rand(100, 6)
julia&gt; m2 = DoubleMachineLearning(X, T, Y, W=W)
julia&gt; estimate_causal_effect!(m2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/estimators.jl#L367-L382">source</a></section><section><div><pre><code class="nohighlight hljs">estimate_causal_effect!(s)</code></pre><p>Estimate the CATE using an S-learner.</p><p><strong>References</strong></p><p>For an overview of S-learning see:     Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for      estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of the      national academy of sciences 116, no. 10 (2019): 4156-4165.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m4 = SLearner(X, T, Y)
julia&gt; estimate_causal_effect!(m4)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L417-L434">source</a></section><section><div><pre><code class="nohighlight hljs">estimate_causal_effect!(t)</code></pre><p>Estimate the CATE using an T-learner.</p><p><strong>References</strong></p><p>For an overview of T-learning see:     Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for      estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of the      national academy of sciences 116, no. 10 (2019): 4156-4165.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m5 = TLearner(X, T, Y)
julia&gt; estimate_causal_effect!(m5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L441-L458">source</a></section><section><div><pre><code class="nohighlight hljs">estimate_causal_effect!(x)</code></pre><p>Estimate the CATE using an X-learner.</p><p><strong>References</strong></p><p>For an overview of X-learning see:     Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for      estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of the      national academy of sciences 116, no. 10 (2019): 4156-4165.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = XLearner(X, T, Y)
julia&gt; estimate_causal_effect!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L475-L492">source</a></section><section><div><pre><code class="nohighlight hljs">estimate_causal_effect!(R)</code></pre><p>Estimate the CATE using an R-learner.</p><p><strong>References</strong></p><p>For an overview of R-learning see:     Nie, Xinkun, and Stefan Wager. &quot;Quasi-oracle estimation of heterogeneous treatment      effects.&quot; Biometrika 108, no. 2 (2021): 299-319.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = RLearner(X, T, Y)
julia&gt; estimate_causal_effect!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L506-L522">source</a></section><section><div><pre><code class="nohighlight hljs">estimate_causal_effect!(DRE)</code></pre><p>Estimate the CATE using a doubly robust learner.</p><p><strong>References</strong></p><p>For details on how this method estimates the CATE see:     Kennedy, Edward H. &quot;Towards optimal doubly robust estimation of heterogeneous causal      effects.&quot; Electronic Journal of Statistics 17, no. 2 (2023): 3008-3049.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y =  rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = DoublyRobustLearner(X, T, Y)
julia&gt; estimate_causal_effect!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metalearners.jl#L545-L561">source</a></section></article><h2 id="Inference"><a class="docs-heading-anchor" href="#Inference">Inference</a><a id="Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Inference" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.summarize" href="#CausalELM.summarize"><code>CausalELM.summarize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">summarize(mod, kwargs...)</code></pre><p>Get a summary from a CausalEstimator or Metalearner.</p><p><strong>Arguments</strong></p><ul><li><code>mod::Union{CausalEstimator, Metalearner}</code>: a model to summarize.</li></ul><p><strong>Keywords</strong></p><ul><li><code>n::Int=1000</code>: the number of iterations to generate the numll distribution for    randomization inference if inference is true.</li><li><code>inference::Bool</code>=false: wheteher calculate p-values and standard errors.</li><li><code>mean_effect::Bool=true</code>: whether to estimate the mean or cumulative effect for an    interrupted time series estimator.</li></ul><p><strong>Notes</strong></p><p>p-values and standard errors are estimated using approximate randomization inference. If set  to true, this procedure takes a long time due to repeated matrix inversions. You can greatly  speed this up by setting to a lower number and launching Julia with more threads.</p><p><strong>References</strong></p><p>For a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, T, Y = rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(100)
julia&gt; m1 = GComputation(X, T, Y)
julia&gt; estimate_causal_effect!(m1)
julia&gt; summarize(m1)

julia&gt; m2 = RLearner(X, T, Y)
julia&gt; estimate_causal_effect(m2)
julia&gt; summarize(m2)

julia&gt; m3 = SLearner(X, T, Y)
julia&gt; estimate_causal_effect!(m3)
julia&gt; summarise(m3)  # British spelling works too!</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/inference.jl#L3-L42">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.generate_null_distribution" href="#CausalELM.generate_null_distribution"><code>CausalELM.generate_null_distribution</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">generate_null_distribution(mod, n)
generate_null_distribution(mod, n, mean_effect)</code></pre><p>Generate a null distribution for the treatment effect of G-computation, double machine  learning, or metalearning.</p><p><strong>Arguments</strong></p><ul><li><code>mod::Any</code>: model to summarize.</li><li><code>n::Int=100</code>: number of iterations to generate the null distribution for randomization    inference.</li><li><code>mean_effect::Bool=true</code>: whether to estimate the mean or cumulative effect for an    interrupted time series estimator.</li></ul><p><strong>Notes</strong></p><p>This method estimates the same model that is provided using random permutations of the  treatment assignment to generate a vector of estimated effects under different treatment regimes. When mod is a metalearner the null statistic is the difference is the ATE.</p><p>Note that lowering the number of iterations increases the probability of failing to reject the null hypothesis.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t, y = rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(1:100, 100, 1)
julia&gt; g_computer = GComputation(x, t, y)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; generate_null_distribution(g_computer, 500)
julia&gt; x₀, y₀, x₁, y₁ = rand(1:100, 100, 5), rand(100), rand(10, 5), rand(10)
julia&gt; its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)
julia&gt; estimate_causal_effect!(its)
julia&gt; generate_null_distribution(its, 10)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/inference.jl#L157-L190">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.quantities_of_interest" href="#CausalELM.quantities_of_interest"><code>CausalELM.quantities_of_interest</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">quantities_of_interest(mod, n)
quantities_of_interest(mod, n, mean_effect)</code></pre><p>Generate a p-value and standard error through randomization inference</p><p>This method generates a null distribution of treatment effects by reestimating treatment  effects from permutations of the treatment vector and estimates a p-value and standard from the generated distribution.</p><p>Note that lowering the number of iterations increases the probability of failing to reject the null hypothesis.</p><p>For a primer on randomization inference see:     https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t, y = rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(1:100, 100, 1)
julia&gt; g_computer = GComputation(x, t, y)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; quantities_of_interest(g_computer, 1000)
julia&gt; x₀, y₀, x₁, y₁ = rand(1:100, 100, 5), rand(100), rand(10, 5), rand(10)
julia&gt; its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)
julia&gt; estimate_causal_effect!(its)
julia&gt; quantities_of_interest(its, 10)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/inference.jl#L233-L260">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.confidence_interval" href="#CausalELM.confidence_interval"><code>CausalELM.confidence_interval</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">confidence_interval(null_dist, effect)</code></pre><p>Compute 95% confidence intervals via randomization inference.</p><p>This function should not be called directly by the user.</p><p>For a primer on randomization inference see:     https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t, y = rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(1:100, 100, 1)
julia&gt; g_computer = GComputation(x, t, y)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; null_dist = CausalELM.generate_null_distribution(g_computer, 1000)
julia&gt; confidence_interval(null_dist, g_computer.causal_effect)
(-0.45147664642089147, 0.45147664642089147)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/inference.jl#L280-L299">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.p_value_and_std_err" href="#CausalELM.p_value_and_std_err"><code>CausalELM.p_value_and_std_err</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">p_value_and_std_err(null_dist, test_stat)</code></pre><p>Compute the p-value for a given test statistic and null distribution.</p><p>This is an approximate method based on randomization inference that does not assume any  parametric form of the null distribution.</p><p>For a primer on randomization inference see:     https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t, y = rand(100, 5), [rand()&lt;0.4 for i in 1:100], rand(1:100, 100, 1)
julia&gt; g_computer = GComputation(x, t, y)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; null_dist = CausalELM.generate_null_distribution(g_computer, 1000)
julia&gt; p_value_and_std_err(null_dist, CausalELM.mean(null_dist))
(0.3758916871866841, 0.1459779344550146)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/inference.jl#L328-L348">source</a></section></article><h2 id="Model-Validation"><a class="docs-heading-anchor" href="#Model-Validation">Model Validation</a><a id="Model-Validation-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Validation" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.validate" href="#CausalELM.validate"><code>CausalELM.validate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">validate(its; kwargs...)</code></pre><p>Test the validity of an estimated interrupted time series analysis.</p><p><strong>Arguments</strong></p><ul><li><code>its::InterruptedTimeSeries</code>: an interrupted time seiries estimator.</li></ul><p><strong>Keywords</strong></p><ul><li><code>n::Int</code>: number of times to simulate a confounder.</li><li><code>low::Float64</code>=0.15: minimum proportion of data points to include before or after the    tested break in the Wald supremum test.</li><li><code>high::Float64=0.85</code>: maximum proportion of data points to include before or after the    tested break in the Wald supremum test.</li></ul><p><strong>Notes</strong></p><p>This method coducts a Chow Test, a Wald supremeum test, and tests the model&#39;s sensitivity to  confounders. The Chow Test tests for structural breaks in the covariates between the time  before and after the event. p-values represent the proportion of times the magnitude of the  break in a covariate would have been greater due to chance. Lower p-values suggest a higher  probability the event effected the covariates and they cannot provide unbiased  counterfactual predictions. The Wald supremum test finds the structural break with the  highest Wald statistic. If this is not the same as the hypothesized break, it could indicate  an anticipation effect, a confounding event, or that the intervention or policy took place  in multiple phases. p-values represent the proportion of times we would see a larger Wald  statistic if the data points were randomly allocated to pre and post-event periods for the  predicted structural break. Ideally, the hypothesized break will be the same as the  predicted break and it will also have a low p-value. The omitted predictors test adds  normal random variables with uniform noise as predictors. If the included covariates are  good predictors of the counterfactual outcome, adding irrelevant predictors should not have  a large effect on the predicted counterfactual outcomes or the estimated effect.</p><p>This method does not implement the second test in Baicker and Svoronos because the estimator  in this package models the relationship between covariates and the outcome and uses an  extreme learning machine instead of linear regression, so variance in the outcome across  different bins is not much of an issue.</p><p><strong>References</strong></p><p>For more details on the assumptions and validity of interrupted time series designs, see:     Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single      interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.</p><p>For a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X₀, Y₀, X₁, Y₁ = rand(100, 5), rand(100), rand(10, 5), rand(10)
julia&gt; m1 = InterruptedTimeSeries(X₀, Y₀, X₁, Y₁)
julia&gt; estimate_causal_effect!(m1)
julia&gt; validate(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L1-L53">source</a></section><section><div><pre><code class="nohighlight hljs">validate(m; kwargs)</code></pre><p><strong>Arguments</strong></p><ul><li><code>m::Union{CausalEstimator, Metalearner}</code>: model to validate/test the assumptions of.</li></ul><p><strong>Keywords</strong></p><ul><li><code>devs=::Any</code>: iterable of deviations from which to generate noise to simulate violations    of the counterfactual consistency assumption.</li><li><code>num_iterations=10::Int: number of times to simulate a violation of the counterfactual    consistency assumption.</code></li><li><code>min::Float64</code>=1.0e-6: minimum probability of treatment for the positivity assumption.</li><li><code>high::Float64=1-min</code>: maximum probability of treatment for the positivity assumption.</li></ul><p><strong>Notes</strong></p><p>This method tests the counterfactual consistency, exchangeability, and positivity  assumptions required for causal inference. It should be noted that consistency and  exchangeability are not directly testable, so instead, these tests do not provide definitive  evidence of a violation of these assumptions. To probe the counterfactual consistency  assumption, we simulate counterfactual outcomes that are different from the observed  outcomes, estimate models with the simulated counterfactual outcomes, and take the averages. If the outcome is continuous, the noise for the simulated counterfactuals is drawn from  N(0, dev) for each element in devs, otherwise the default is 0.25, 0.5, 0.75, and 1.0  standard deviations from the mean outcome. For discrete variables, each outcome is replaced  with a different value in the range of outcomes with probability ϵ for each ϵ in devs,  otherwise the default is 0.025, 0.05, 0.075, 0.1. If the average estimate for a given level  of violation differs greatly from the effect estimated on the actual data, then the model is  very sensitive to violations of the counterfactual consistency assumption for that level of  violation. Next, this methods tests the model&#39;s sensitivity to a violation of the  exchangeability assumption by calculating the E-value, which is the minimum strength of  association, on the risk ratio scale, that an unobserved confounder would need to have with  the treatment and outcome variable to fully explain away the estimated effect. Thus, higher  E-values imply the model is more robust to a violation of the exchangeability assumption.  Finally, this method tests the positivity assumption by estimating propensity scores. Rows  in the matrix are levels of covariates that have a zero probability of treatment. If the  matrix is empty, none of the observations have an estimated zero probability of treatment,  which implies the positivity assumption is satisfied.</p><p><strong>References</strong></p><p>For a thorough review of casual inference assumptions see:     Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and      Francis, 2024. </p><p>For more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research:      introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t, y = rand(100, 5), Float64.([rand()&lt;0.4 for i in 1:100]), vec(rand(1:100, 100, 1)) 
julia&gt; g_computer = GComputation(x, t, y, temporal=false)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; validate(g_computer)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L64-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.covariate_independence" href="#CausalELM.covariate_independence"><code>CausalELM.covariate_independence</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">covariate_independence(its; kwargs..)</code></pre><p>Test for independence between covariates and the event or intervention.</p><p><strong>Arguments</strong></p><ul><li><code>its::InterruptedTImeSeries</code>: an interrupted time series estimator.</li></ul><p><strong>Keywords</strong></p><ul><li><code>n::Int</code>: number of permutations for assigning observations to the pre and        post-treatment periods.</li></ul><p>This is a Chow Test for covariates with p-values estimated via randomization inference,  which does not assume a distribution for the outcome variable. The p-values are the  proportion of times randomly assigning observations to the pre or post-intervention period  would have a larger estimated effect on the the slope of the covariates. The lower the  p-values, the more likely it is that the event/intervention effected the covariates and  they cannot provide an unbiased prediction of the counterfactual outcomes.</p><p>For more information on using a Chow Test to test for structural breaks see:     Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single      interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.</p><p>For a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x₀, y₀, x₁, y₁ = (Float64.(rand(1:5, 100, 5)), randn(100), rand(1:5, (10, 5)), 
       randn(10))
julia&gt; its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)
julia&gt; estimate_causal_effect!(its)
julia&gt; covariate_independence(its)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L138-L172">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.omitted_predictor" href="#CausalELM.omitted_predictor"><code>CausalELM.omitted_predictor</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">omitted_predictor(its; kwargs...)</code></pre><p>See how an omitted predictor/variable could change the results of an interrupted time series  analysis.</p><p><strong>Arguments</strong></p><ul><li><code>its::InterruptedTImeSeries</code>: interrupted time seiries estimator.</li></ul><p><strong>Keywords</strong></p><ul><li><code>n::Int</code>: number of times to simulate a confounder.</li></ul><p><strong>Notes</strong></p><p>This method reestimates interrupted time series models with uniform random variables. If the  included covariates are good predictors of the counterfactual outcome, adding a random  variable as a covariate should not have a large effect on the predicted counterfactual  outcomes and therefore the estimated average effect.</p><p>For a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x₀, y₀, x₁, y₁ = (Float64.(rand(1:5, 100, 5)), randn(100), rand(1:5, (10, 5)), randn(10))
julia&gt; its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)
julia&gt; estimate_causal_effect!(its)
julia&gt; omitted_predictor(its)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L190-L218">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.sup_wald" href="#CausalELM.sup_wald"><code>CausalELM.sup_wald</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">sup_wald(its; kwargs)</code></pre><p>Check if the predicted structural break is the hypothesized structural break.</p><p><strong>Arguments</strong></p><ul><li><code>its::InterruptedTimeSeries</code>: interrupted time seiries estimator.</li></ul><p><strong>Keywords</strong></p><ul><li><code>n::Int</code>: number of times to simulate a confounder.</li><li><code>low::Float64</code>=0.15: minimum proportion of data points to include before or after the        tested break in the Wald supremum test.</li><li><code>high::Float64=0.85</code>: maximum proportion of data points to include before or after the        tested break in the Wald supremum test.</li></ul><p><strong>Notes</strong></p><p>This method conducts Wald tests and identifies the structural break with the highest Wald  statistic. If this break is not the same as the hypothesized break, it could indicate an  anticipation effect, confounding by some other event or intervention, or that the  intervention or policy took place in multiple phases. p-values are estimated using  approximate randomization inference and represent the proportion of times we would see a  larger Wald statistic if the data points were randomly allocated to pre and post-event  periods for the predicted structural break.</p><p><strong>References</strong></p><p>For more information on using a Chow Test to test for structural breaks see:     Baicker, Katherine, and Theodore Svoronos. Testing the validity of the single      interrupted time series design. No. w26080. National Bureau of Economic Research, 2019.</p><p>For a primer on randomization inference see:      https://www.mattblackwell.org/files/teaching/s05-fisher.pdf</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x₀, y₀, x₁, y₁ = (Float64.(rand(1:5, 100, 5)), randn(100), rand(1:5, (10, 5)), 
       randn(10))
julia&gt; its = InterruptedTimeSeries(x₀, y₀, x₁, y₁)
julia&gt; estimate_causal_effect!(its)
julia&gt; sup_wald(its)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L248-L288">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.p_val" href="#CausalELM.p_val"><code>CausalELM.p_val</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">p_val(x, y, β; kwargs...)</code></pre><p>Estimate the p-value for the hypothesis that an event had a statistically significant effect  on the slope of a covariate using randomization inference.</p><p><strong>Arguments</strong></p><ul><li><code>x::Array{&lt;:Real}</code>: covariates.</li><li><code>y::Array{&lt;:Real}</code>: outcome.</li><li><code>β::Array{&lt;:Real}</code>=0.15: fitted weights.</li></ul><p><strong>Keywords</strong></p><ul><li><code>two_sided::Bool=false</code>: whether to conduct a one-sided hypothesis test.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, y, β = reduce(hcat, (float(rand(0:1, 10)), ones(10))), rand(10), 0.5
julia&gt; p_val(x, y, β)
julia&gt; p_val(x, y, β; n=100, two_sided=true)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L318-L338">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.counterfactual_consistency" href="#CausalELM.counterfactual_consistency"><code>CausalELM.counterfactual_consistency</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">counterfactual_consistency(m; kwargs...)</code></pre><p><strong>Arguments</strong></p><ul><li><code>m::Union{CausalEstimator, Metalearner}</code>: model to validate/test the assumptions of.</li></ul><p><strong>Keywords</strong></p><ul><li><code>num_devs=(0.25, 0.5, 0.75, 1.0)::Tuple</code>: number of standard deviations from which to    generate noise from a normal distribution to simulate violations of the counterfactual    consistency assumption.</li><li><code>num_iterations=10::Int: number of times to simulate a violation of the counterfactual    consistency assumption.</code></li></ul><p><strong>Notes</strong></p><p>Examine the counterfactual consistency assumption. First, this function simulates  counterfactual outcomes that are offset from the outcomes in the dataset by random scalars drawn from a N(0, num<em>std</em>dev). Then, the procedure is repeated num<em>iterations times and  averaged. If the model is a metalearner, then the estimated individual treatment effects  are averaged and the mean CATE is averaged over all the iterations, otherwise the estimated  treatment effect is averaged over the iterations. The previous steps are repeated for each  element in num</em>devs.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t = rand(100, 5), Float64.([rand()&lt;0.4 for i in 1:100]
julia&gt; y = vec(rand(1:100, 100, 1)))
julia&gt; g_computer = GComputation(x, t, y, temporal=false)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; counterfactual_consistency(g_computer)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L360-L390">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.simulate_counterfactual_violations" href="#CausalELM.simulate_counterfactual_violations"><code>CausalELM.simulate_counterfactual_violations</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">simulate_counterfactual_violations(y, dev)</code></pre><p><strong>Arguments</strong></p><ul><li><code>y::Vector{&lt;:Real}</code>: vector of real-valued outcomes.</li><li><code>dev::Float64</code>: deviation of the observed outcomes from the true counterfactual outcomes.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t, y = rand(100, 5), Float64.([rand()&lt;0.4 for i in 1:100]), vec(rand(1:100, 100, 1)) 
julia&gt; g_computer = GComputation(x, t, y, temporal=false)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; simulate_counterfactual_violations(g_computer)
-0.7748591231872396</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L415-L430">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.exchangeability" href="#CausalELM.exchangeability"><code>CausalELM.exchangeability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">exchangeability(model)</code></pre><p>Test the sensitivity of a G-computation or doubly robust estimator or metalearner to a  violation of the exchangeability assumption.</p><p><strong>References</strong></p><p>For more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research:      introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t = rand(100, 5), Float64.([rand()&lt;0.4 for i in 1:100]
julia&gt; y = vec(rand(1:100, 100, 1)))
julia&gt; g_computer = GComputation(x, t, y, temporal=false)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; e_value(g_computer)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L443-L462">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.e_value" href="#CausalELM.e_value"><code>CausalELM.e_value</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">e_value(model)</code></pre><p>Test the sensitivity of an estimator to a violation of the exchangeability assumption.</p><p><strong>References</strong></p><p>For more information on the E-value test see:     VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research:      introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t = rand(100, 5), Float64.([rand()&lt;0.4 for i in 1:100]
julia&gt; y = vec(rand(1:100, 100, 1)))
julia&gt; g_computer = GComputation(x, t, y, temporal=false)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; e_value(g_computer)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L465-L483">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.binarize" href="#CausalELM.binarize"><code>CausalELM.binarize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">binarize(x, cutoff)</code></pre><p>Convert a vector of counts or a continuous vector to a binary vector.</p><p><strong>Arguments</strong></p><ul><li><code>x::Any</code>: interable of numbers to binarize.</li><li><code>x::Any</code>: threshold after which numbers are converted to 1 and befrore which are converted    to 0.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.binarize([1, 2, 3], 2)
3-element Vector{Int64}:
 0
 0
 1</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L494-L512">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.risk_ratio" href="#CausalELM.risk_ratio"><code>CausalELM.risk_ratio</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">risk_ratio(model)</code></pre><p>Calculate the risk ratio for an estimated model.</p><p><strong>Notes</strong></p><p>If the treatment variable is not binary and the outcome variable is not continuous then the  treatment variable will be binarized.</p><p><strong>References</strong></p><p>For more information on how other quantities of interest are converted to risk ratios see:     VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research:      introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t = rand(100, 5), Float64.([rand()&lt;0.4 for i in 1:100]
julia&gt; y = vec(rand(1:100, 100, 1)))
julia&gt; g_computer = GComputation(x, t, y, temporal=false)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; risk_ratio(g_computer)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L523-L545">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.positivity" href="#CausalELM.positivity"><code>CausalELM.positivity</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">positivity(model, [,min], [,max])</code></pre><p>Find likely violations of the positivity assumption.</p><p><strong>Notes</strong></p><p>This method uses an extreme learning machine or regularized extreme learning machine to  estimate probabilities of treatment. The returned matrix, which may be empty, are the  covariates that have a (near) zero probability of treatment or near zero probability of  being assigned to the control group, whith their entry in the last column being their  estimated treatment probability. In other words, they likely violate the positivity  assumption.</p><p><strong>Arguments</strong></p><ul><li><code>model::Union{CausalEstimator, Metalearner}</code>: a model to validate/test the assumptions of.</li><li><code>min::Float64</code>=1.0e-6: minimum probability of treatment for the positivity assumption.</li><li><code>high::Float64=1-min</code>: the maximum probability of treatment for the positivity assumption.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, t = rand(100, 5), Float64.([rand()&lt;0.4 for i in 1:100]
julia&gt; y = vec(rand(1:100, 100, 1)))
julia&gt; g_computer = GComputation(x, t, y, temporal=false)
julia&gt; estimate_causal_effect!(g_computer)
julia&gt; positivity(g_computer)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/model_validation.jl#L629-L655">source</a></section></article><h2 id="Validation-Metrics"><a class="docs-heading-anchor" href="#Validation-Metrics">Validation Metrics</a><a id="Validation-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Validation-Metrics" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.mse" href="#CausalELM.mse"><code>CausalELM.mse</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">mse(y, ŷ)</code></pre><p>Calculate the mean squared error</p><p>See also <a href="#CausalELM.mae"><code>mae</code></a>.</p><p>Examples</p><pre><code class="language-julia-repl hljs">julia&gt; mse([-1.0, -1.0, -1.0], [1.0, 1.0, 1.0])
4.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metrics.jl#L3-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.mae" href="#CausalELM.mae"><code>CausalELM.mae</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">mae(y, ŷ)</code></pre><p>Calculate the mean absolute error</p><p>See also <a href="#CausalELM.mse"><code>mse</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; mae([-1.0, -1.0, -1.0], [1.0, 1.0, 1.0])
2.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metrics.jl#L24-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.accuracy" href="#CausalELM.accuracy"><code>CausalELM.accuracy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">accuracy(y, ŷ)</code></pre><p>Calculate the accuracy for a classification task</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; accuracy([1, 1, 1, 1], [0, 1, 1, 0])
0.5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metrics.jl#L45-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.precision" href="#CausalELM.precision"><code>CausalELM.precision</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">precision(y, ŷ)</code></pre><p>Calculate the precision for a classification task</p><p>See also <a href="#CausalELM.recall"><code>recall</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.precision([0, 1, 0, 0], [0, 1, 1, 0])
1.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metrics.jl#L70-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.recall" href="#CausalELM.recall"><code>CausalELM.recall</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">recall(y, ŷ)</code></pre><p>Calculate the recall for a classification task</p><p>See also <a href="#CausalELM.precision"><code>CausalELM.precision</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; recall([1, 2, 1, 3, 0], [2, 2, 2, 3, 1])
0.5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metrics.jl#L97-L109">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.F1" href="#CausalELM.F1"><code>CausalELM.F1</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">F1(y, ŷ)</code></pre><p>Calculate the F1 score for a classification task</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; F1([1, 2, 1, 3, 0], [2, 2, 2, 3, 1])
0.4</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metrics.jl#L124-L134">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.confusion_matrix" href="#CausalELM.confusion_matrix"><code>CausalELM.confusion_matrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">confusion_matrix(y, ŷ)</code></pre><p>Generate a confusion matrix</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.confusion_matrix([1, 1, 1, 1, 0], [1, 1, 1, 1, 0])
2×2 Matrix{Int64}:
 1  0
 0  4</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/metrics.jl#L140-L152">source</a></section></article><h2 id="Extreme-Learning-Machines"><a class="docs-heading-anchor" href="#Extreme-Learning-Machines">Extreme Learning Machines</a><a id="Extreme-Learning-Machines-1"></a><a class="docs-heading-anchor-permalink" href="#Extreme-Learning-Machines" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.fit!" href="#CausalELM.fit!"><code>CausalELM.fit!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">fit!(model)</code></pre><p>Fit an ExtremeLearner to the data.</p><p><strong>References</strong></p><p>For more details see:      Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. &quot;Extreme learning machine: theory      and applications.&quot; Neurocomputing 70, no. 1-3 (2006): 489-501.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, y = [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0], [0.0, 1.0, 0.0, 1.0]
julia&gt; m1 = ExtremeLearner(x, y, 10, σ)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L91-L106">source</a></section><section><div><pre><code class="nohighlight hljs">fit!(model)</code></pre><p>Fit an ensemble of ExtremeLearners to the data. </p><p><strong>Arguments</strong></p><ul><li><code>model::ELMEnsemble</code>: ensemble of ExtremeLearners to fit.</li></ul><p><strong>Notes</strong></p><p>This uses the same bagging approach as random forests when the labels are continuous but  uses the average predicted probability, rather than voting, for classification.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; X, Y =  rand(100, 5), rand(100)
julia&gt; m1 = ELMEnsemble(X, Y, 10, 50, 5, CausalELM.relu)
julia&gt; fit!(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L115-L133">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.predict" href="#CausalELM.predict"><code>CausalELM.predict</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">predict(model, X)</code></pre><p>Use an ExtremeLearningMachine or ELMEnsemble to make predictions.</p><p><strong>Notes</strong></p><p>If using an ensemble to make predictions, this method returns a maxtirs where each row is a prediction and each column is a model.</p><p><strong>References</strong></p><p>For more details see:      Huang G-B, Zhu Q-Y, Siew C. Extreme learning machine: theory and applications.      Neurocomputing. 2006;70:489–501. https://doi.org/10.1016/j.neucom.2005.12.126</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, y = [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0], [0.0, 1.0, 0.0, 1.0]
julia&gt; m1 = ExtremeLearner(x, y, 10, σ)
julia&gt; fit!(m1, sigmoid)
julia&gt; predict(m1, [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0])

julia&gt; m2 = ELMEnsemble(X, Y, 10, 50, 5, CausalELM.relu)
julia&gt; fit!(m2)
julia&gt; predict(m2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L140-L165">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.predict_counterfactual!" href="#CausalELM.predict_counterfactual!"><code>CausalELM.predict_counterfactual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">predict_counterfactual!(model, X)</code></pre><p>Use an ExtremeLearningMachine to predict the counterfactual.</p><p><strong>Notes</strong></p><p>This should be run with the observed covariates. To use synthtic data for what-if scenarios  use predict.</p><p>See also <a href="#CausalELM.predict"><code>predict</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, y = [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0], [0.0, 1.0, 0.0, 1.0]
julia&gt; m1 = ExtremeLearner(x, y, 10, σ)
julia&gt; f1 = fit(m1, sigmoid)
julia&gt; predict_counterfactual!(m1, [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L185-L203">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.placebo_test" href="#CausalELM.placebo_test"><code>CausalELM.placebo_test</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">placebo_test(model)</code></pre><p>Conduct a placebo test.</p><p><strong>Notes</strong></p><p>This method makes predictions for the post-event or post-treatment period using data  in the pre-event or pre-treatment period and the post-event or post-treament. If there is a statistically significant difference between these predictions the study design may be flawed. Due to the multitude of significance tests for time series data, this function returns the predictions but does not test for statistical significance.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; x, y = [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0], [0.0, 1.0, 0.0, 1.0]
julia&gt; m1 = ExtremeLearner(x, y, 10, σ)
julia&gt; f1 = fit(m1, sigmoid)
julia&gt; predict_counterfactual(m1, [1.0 1.0; 0.0 1.0; 0.0 0.0; 1.0 0.0])
julia&gt; placebo_test(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L210-L230">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.set_weights_biases" href="#CausalELM.set_weights_biases"><code>CausalELM.set_weights_biases</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">set_weights_biases(model)</code></pre><p>Calculate the weights and biases for an extreme learning machine.</p><p><strong>Notes</strong></p><p>Initialization is done using uniform Xavier initialization.</p><p><strong>References</strong></p><p>For details see;     Huang, Guang-Bin, Qin-Yu Zhu, and Chee-Kheong Siew. &quot;Extreme learning machine: theory      and applications.&quot; Neurocomputing 70, no. 1-3 (2006): 489-501.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; m1 = RegularizedExtremeLearner(x, y, 10, σ)
julia&gt; set_weights_biases(m1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/models.jl#L239-L257">source</a></section></article><h2 id="Utility-Functions"><a class="docs-heading-anchor" href="#Utility-Functions">Utility Functions</a><a id="Utility-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Utility-Functions" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CausalELM.var_type" href="#CausalELM.var_type"><code>CausalELM.var_type</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">var_type(x)</code></pre><p>Determine the type of variable held by a vector.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.var_type([1, 2, 3, 2, 3, 1, 1, 3, 2])
CausalELM.Count()</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L16-L26">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.mean" href="#CausalELM.mean"><code>CausalELM.mean</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">mean(x)</code></pre><p>Calculate the mean of a vector.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.mean([1, 2, 3, 4])
2.5</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L39-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.var" href="#CausalELM.var"><code>CausalELM.var</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">var(x)</code></pre><p>Calculate the (sample) mean of a vector.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.var([1, 2, 3, 4])
1.6666666666666667</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L52-L62">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.one_hot_encode" href="#CausalELM.one_hot_encode"><code>CausalELM.one_hot_encode</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">one_hot_encode(x)</code></pre><p>One hot encode a categorical vector for multiclass classification.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.one_hot_encode([1, 2, 3, 4, 5])
5×5 Matrix{Float64}:
 1.0  0.0  0.0  0.0  0.0
 0.0  1.0  0.0  0.0  0.0
 0.0  0.0  1.0  0.0  0.0
 0.0  0.0  0.0  1.0  0.0
 0.0  0.0  0.0  0.0  1.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L65-L80">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.clip_if_binary" href="#CausalELM.clip_if_binary"><code>CausalELM.clip_if_binary</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">clip_if_binary(x, var)</code></pre><p>Constrain binary values between 1e-7 and 1 - 1e-7, otherwise return the original values.</p><p><strong>Arguments</strong></p><ul><li><code>x::Array</code>: array to clip if it is binary.</li><li><code>var</code>: type of x based on calling var_type.</li></ul><p>See also <a href="#CausalELM.var_type"><code>var_type</code></a>.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.clip_if_binary([1.2, -0.02], CausalELM.Binary())
2-element Vector{Float64}:
 1.0
 0.0

julia&gt; CausalELM.clip_if_binary([1.2, -0.02], CausalELM.Count())
2-element Vector{Float64}:
  1.2
 -0.02</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L86-L109">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.@model_config" href="#CausalELM.@model_config"><code>CausalELM.@model_config</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">model_config(effect_type)</code></pre><p>Generate fields common to all CausalEstimator, Metalearner, and InterruptedTimeSeries  structs.</p><p><strong>Arguments</strong></p><ul><li><code>effect_type::String</code>: &quot;average<em>effect&quot; or &quot;individual</em>effect&quot; to define fields for either    models that estimate average effects or the CATE.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; struct TestStruct CausalELM.@model_config average_effect end
julia&gt; TestStruct(&quot;ATE&quot;, false, &quot;classification&quot;, true, relu, F1, 2, 10, 5, 100, 5, 5, 0.25)
TestStruct(&quot;ATE&quot;, false, &quot;classification&quot;, true, relu, F1, 2, 10, 5, 100, 5, 5, 0.25)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L112-L128">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.@standard_input_data" href="#CausalELM.@standard_input_data"><code>CausalELM.@standard_input_data</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">standard_input_data()</code></pre><p>Generate fields common to all CausalEstimators except DoubleMachineLearning and all  Metalearners except RLearner and DoublyRobustLearner.</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; struct TestStruct CausalELM.@standard_input_data end
julia&gt; TestStruct([5.2], [0.8], [0.96])
TestStruct([5.2], [0.8], [0.96])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L154-L166">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.generate_folds" href="#CausalELM.generate_folds"><code>CausalELM.generate_folds</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">generate_folds(X, T, Y, folds)</code></pre><p>Create folds for cross validation.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; xfolds, tfolds, yfolds = CausalELM.generate_folds(zeros(4, 2), zeros(4), ones(4), 2)
([[0.0 0.0], [0.0 0.0; 0.0 0.0; 0.0 0.0]], [[0.0], [0.0, 0.0, 0.0]], [[1.0], [1.0, 1.0, 1.0]])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L176-L186">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CausalELM.convert_if_table" href="#CausalELM.convert_if_table"><code>CausalELM.convert_if_table</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">convert_if_table(t)</code></pre><p>Convert a data structure that implements the Tables.jl API to a matrix, otherwise return the      original data.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; CausalELM.convert_if_table([1 1; 1 1])
2×2 Matrix{Int64}:
 1  1
 1  1</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/dscolby/CausalELM.jl/blob/328138c545d57f1f3542fdf7c68f96731e2fa4cd/src/utilities.jl#L210-L223">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../guide/metalearners/">« Metalearners</a><a class="docs-footer-nextpage" href="../contributing/">Contributing »</a><div class="flexbox-break"></div><p class="footer-message">© 2024 Darren Colby</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 17 December 2024 03:31">Tuesday 17 December 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
