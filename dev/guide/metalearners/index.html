<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Metalearners · CausalELM</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://dscolby.github.io/CausalELM.jl/guide/metalearners/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.jpg" alt="CausalELM logo"/></a><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">CausalELM</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../estimatorselection/">Deciding Which Estimator to Use</a></li><li><a class="tocitem" href="../its/">Interrupted Time Series Estimation</a></li><li><a class="tocitem" href="../gcomputation/">G-computation</a></li><li><a class="tocitem" href="../doublemachinelearning/">Double Machine Learning</a></li><li class="is-active"><a class="tocitem" href>Metalearners</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Initialize-a-Metalearner"><span>Initialize a Metalearner</span></a></li><li class="toplevel"><a class="tocitem" href="#Estimate-the-CATE"><span>Estimate the CATE</span></a></li><li class="toplevel"><a class="tocitem" href="#Get-a-Summary"><span>Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model"><span>Step 4: Validate the Model</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Getting Started</a></li><li class="is-active"><a href>Metalearners</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Metalearners</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dscolby/CausalELM.jl/blob/main/docs/src/guide/metalearners.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Metalearners"><a class="docs-heading-anchor" href="#Metalearners">Metalearners</a><a id="Metalearners-1"></a><a class="docs-heading-anchor-permalink" href="#Metalearners" title="Permalink"></a></h1><p>Instead of knowing the average causal effect, we might want to know which units benefit and  which units lose by being exposed to a treatment. For example, a cash transfer program might  motivate some people to work harder and incentivize others to work less. Thus, we might want  to know how the cash transfer program affects individuals instead of it average affect on  the population. To do so, we can use metalearners. Depending on the scenario, we may want to  use an S-learner, T-learner, X-learner, R-learner, or doubly robust learner. The basic steps  to use all five metalearners are below. The difference between the metalearners is how they  estimate the CATE and what types of variables they can handle. In the case of S, T, X, and  doubly robust learners, they can only handle binary treatments. On the other hand,  R-learners can handle binary, categorical, count, or continuous treatments but only supports  continuous outcomes.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If regularized is set to true then the ridge penalty will be estimated using generalized  cross validation where the maximum number of iterations is 2 * folds for the successive  halving procedure. However, if the penalty in on iteration is approximately the same as  in the previous penalty, then the procedure will stop early.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a deeper dive on S-learning, T-learning, and X-learning see:</p><pre><code class="nohighlight hljs">Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. &quot;Metalearners for 
estimating heterogeneous treatment effects using machine learning.&quot; Proceedings of the 
national academy of sciences 116, no. 10 (2019): 4156-4165.</code></pre><p>To learn more about R-learning see:</p><pre><code class="nohighlight hljs">Nie, Xinkun, and Stefan Wager. &quot;Quasi-oracle estimation of heterogeneous treatment 
effects.&quot; Biometrika 108, no. 2 (2021): 299-319.</code></pre><p>To see the details out doubly robust estimation implemented in CausalELM see:     Kennedy, Edward H. &quot;Towards optimal doubly robust estimation of heterogeneous causal      effects.&quot; Electronic Journal of Statistics 17, no. 2 (2023): 3008-3049.</p></div></div><h1 id="Initialize-a-Metalearner"><a class="docs-heading-anchor" href="#Initialize-a-Metalearner">Initialize a Metalearner</a><a id="Initialize-a-Metalearner-1"></a><a class="docs-heading-anchor-permalink" href="#Initialize-a-Metalearner" title="Permalink"></a></h1><p>S-learners, T-learners, X-learners, R-learners, and doubly robust estimators all take at  least three arguments: an array of covariates, a vector of outcomes, and a vector of  treatment statuses. S, T, X, and doubly robust learners support binary treatment variables  and binary, continuous, count, or time to event outcomes. The R-learning estimator supports  binary, continuous, or count treatment variables and binary, continuous, count, or time to  event outcomes.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Internally, the outcome and treatment models of the metalearners are treated as a regression  since extreme learning machines minimize the MSE. This means that predicted treatments and  outcomes under treatment and control groups could fall outside [0, 1], although this is not  likely in practice. To deal with this, predicted binary variables are automatically clipped to  [0.0000001, 0.9999999].This also means that count outcomes will be predicted as continuous  variables.</p></div></div><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>Additional options can be specified for each type of metalearner using its keyword arguments.</p></div></div><pre><code class="language-julia hljs"># Generate data to use
X, Y, T =  rand(1000, 5), rand(1000), [rand()&lt;0.4 for i in 1:1000]

# We can also speficy potential confounders that we are not interested in
W = randn(1000, 6)

# We could also use DataFrames
# using DataFrames
# X = DataFrame(x1=rand(1000), x2=rand(1000), x3=rand(1000), x4=rand(1000), x5=rand(1000))
# T, Y = DataFrame(t=[rand()&lt;0.4 for i in 1:1000]), DataFrame(y=rand(1000))

s_learner = SLearner(X, Y, T)
t_learner = TLearner(X, Y, T)
x_learner = XLearner(X, Y, T)
r_learner = RLearner(X, Y, T, W=W)
dr_learner = DoublyRobustLearner(X, T, Y, W=W)</code></pre><h1 id="Estimate-the-CATE"><a class="docs-heading-anchor" href="#Estimate-the-CATE">Estimate the CATE</a><a id="Estimate-the-CATE-1"></a><a class="docs-heading-anchor-permalink" href="#Estimate-the-CATE" title="Permalink"></a></h1><p>We can estimate the CATE for all the models by passing them to estimate<em>causal</em>effect!.</p><pre><code class="language-julia hljs">estimate_causal_effect!(s_learner)
estimate_causal_effect!(t_learner)
estimate_causal_effect!(x_learner)
estimate_causal_effect!(r_learner)
estimate_causal_effect!(dr_lwarner)</code></pre><h1 id="Get-a-Summary"><a class="docs-heading-anchor" href="#Get-a-Summary">Get a Summary</a><a id="Get-a-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Get-a-Summary" title="Permalink"></a></h1><p>We can get a summary of the models that includes p0values and standard errors for the  average treatment effect by passing the models to the summarize method.</p><p>Calling the summarize methodd returns a dictionary with the estimator&#39;s task (regression or  classification), the quantity of interest being estimated (CATE), whether the model  uses an L2 penalty, the activation function used in the model&#39;s outcome predictors, whether  the data is temporal, the validation metric used for cross validation to find the best  number of neurons, the number of neurons used in the ELMs used by the estimator, the number  of neurons used in the ELM used to learn a mapping from number of neurons to validation  loss during cross validation, the causal effect, standard error, and p-value for the ATE.</p><pre><code class="language-julia hljs">summarize(s_learner)
summarize(t_learner)
summarize(x_learner)
summarize(r_learner)
summarize(dr_learner)</code></pre><h2 id="Step-4:-Validate-the-Model"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model">Step 4: Validate the Model</a><a id="Step-4:-Validate-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model" title="Permalink"></a></h2><p>We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we simulate counterfactual outcomes that are  different from the observed outcomes, estimate models with the simulated counterfactual  outcomes, and take the averages. If the outcome is continuous, the noise for the simulated  counterfactuals is drawn from N(0, dev) for each element in devs, otherwise the default is  0.25, 0.5, 0.75, and 1.0 standard deviations from the mean outcome. For discrete variables,  each outcome is replaced with a different value in the range of outcomes with probability ϵ  for each ϵ in devs, otherwise the default is 0.025, 0.05, 0.075, 0.1. If the average  estimate for a given level of violation differs greatly from the effect estimated on the  actual data, then the model is very sensitive to violations of the counterfactual  consistency assumption for that level of violation. Next, this method tests the model&#39;s  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  or near zero probability of treatment. If the matrix is empty, none of the observations have  an estimated zero probability of treatment, which implies the positivity assumption is  satisfied.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>One can also specify the maxium number of possible treatments to consider for the causal  consistency assumption and the minimum and maximum probabilities of treatment for the  positivity assumption with the num_treatments, min, and max keyword arguments.</p></div></div><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>Obtaining correct estimates is dependent on meeting the assumptions for interrupted time  series estimation. If the assumptions are not met then any estimates may be biased and  lead to incorrect conclusions.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a thorough review of casual inference assumptions see:</p><pre><code class="nohighlight hljs">Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and 
Francis, 2024.</code></pre><p>For more information on the E-value test see:</p><pre><code class="nohighlight hljs">VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research: 
introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</code></pre></div></div><pre><code class="language-julia hljs">validate(s_learner)
validate(t_learner)
validate(x_learner)
validate(r_learner)
validate(dr_learner)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../doublemachinelearning/">« Double Machine Learning</a><a class="docs-footer-nextpage" href="../../api/">API »</a><div class="flexbox-break"></div><p class="footer-message">© 2024 Darren Colby</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 18 June 2024 03:03">Tuesday 18 June 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
