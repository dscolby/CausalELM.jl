<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>G-computation · CausalELM</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://dscolby.github.io/CausalELM.jl/guide/gcomputation/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.jpg" alt="CausalELM logo"/></a><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">CausalELM</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../estimatorselection/">Deciding Which Estimator to Use</a></li><li><a class="tocitem" href="../its/">Interrupted Time Series Estimation</a></li><li class="is-active"><a class="tocitem" href>G-computation</a><ul class="internal"><li><a class="tocitem" href="#Step-1:-Initialize-a-Model"><span>Step 1: Initialize a Model</span></a></li><li><a class="tocitem" href="#Step-2:-Estimate-the-Causal-Effect"><span>Step 2: Estimate the Causal Effect</span></a></li><li><a class="tocitem" href="#Step-3:-Get-a-Summary"><span>Step 3: Get a Summary</span></a></li><li><a class="tocitem" href="#Step-4:-Validate-the-Model"><span>Step 4: Validate the Model</span></a></li></ul></li><li><a class="tocitem" href="../doublemachinelearning/">Double Machine Learning</a></li><li><a class="tocitem" href="../metalearners/">Metalearners</a></li><li><a class="tocitem" href="../doublyrobust/">Doubly Robust Estimation</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../release_notes/">Release Notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Getting Started</a></li><li class="is-active"><a href>G-computation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>G-computation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/dscolby/CausalELM.jl/blob/main/docs/src/guide/gcomputation.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="G-Computation"><a class="docs-heading-anchor" href="#G-Computation">G-Computation</a><a id="G-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#G-Computation" title="Permalink"></a></h1><p>In some cases, we may want to know the causal effect of a treatment that varies and is  confounded over time. For example, a doctor might want to know the effect of a treatment  given at multiple times whose status depends on the health of the patient at a given time.  One way to get an unbiased estimate of the causal effect is to use G-computation. The basic  steps for using G-computation in CausalELM are below.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a good overview of G-Computation see:</p><pre><code class="nohighlight hljs">Chatton, Arthur, Florent Le Borgne, Clémence Leyrat, Florence Gillaizeau, Chloé 
Rousseau, Laetitia Barbin, David Laplaud, Maxime Léger, Bruno Giraudeau, and Yohann 
Foucher. &quot;G-computation, propensity score-based methods, and targeted maximum likelihood 
estimator for causal inference with different covariates sets: a comparative simulation 
study.&quot; Scientific reports 10, no. 1 (2020): 9219.</code></pre></div></div><h2 id="Step-1:-Initialize-a-Model"><a class="docs-heading-anchor" href="#Step-1:-Initialize-a-Model">Step 1: Initialize a Model</a><a id="Step-1:-Initialize-a-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Initialize-a-Model" title="Permalink"></a></h2><p>The GComputation method takes at least three arguments: an array of covariates, a vector of  treatment statuses, and an outcome vector. </p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>You can also specify the causal estimand, whether to employ L2 regularization, which  activation function to use, whether the data is of a temporal nature, the metric to use when  using cross validation to find the best number of neurons, the minimum number of neurons to  consider, the maximum number of neurons to consider, the number of folds to use during cross  caidation, and the number of neurons to use in the ELM that learns a mapping from number of  neurons to validation loss. These options are specified with the following keyword  arguments: quantity_of_interest, regularized, activation, temporal, validation_metric,  min_neurons, max_neurons, folds, iterations, and approximator_neurons.</p></div></div><pre><code class="language-julia hljs"># Create some data with a binary treatment
X, T, Y =  rand(1000, 5), [rand()&lt;0.4 for i in 1:1000], rand(1000)

# We could also use DataFrames
# using DataFrames
# X = DataFrame(x1=rand(1000), x2=rand(1000), x3=rand(1000), x4=rand(1000), x5=rand(1000))
# T, Y = DataFrame(t=[rand()&lt;0.4 for i in 1:1000]), DataFrame(y=rand(1000))

g_computer = GComputation(X, T, Y)</code></pre><h2 id="Step-2:-Estimate-the-Causal-Effect"><a class="docs-heading-anchor" href="#Step-2:-Estimate-the-Causal-Effect">Step 2: Estimate the Causal Effect</a><a id="Step-2:-Estimate-the-Causal-Effect-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Estimate-the-Causal-Effect" title="Permalink"></a></h2><p>To estimate the causal effect, we pass the model above to estimatecausaleffect!.</p><pre><code class="language-julia hljs"># Note that we could also estimate the ATT by setting quantity_of_interest=&quot;ATT&quot;
estimate_causal_effect!(g_computer)</code></pre><h2 id="Step-3:-Get-a-Summary"><a class="docs-heading-anchor" href="#Step-3:-Get-a-Summary">Step 3: Get a Summary</a><a id="Step-3:-Get-a-Summary-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Get-a-Summary" title="Permalink"></a></h2><p>We get a summary of the model that includes a p-value and standard error estimated via  asymptotic randomization inference by passing our model to the summarize method.</p><p>Calling the summarize method returns a dictionary with the estimator&#39;s task (regression or  classification), the quantity of interest being estimated (ATE or ATT), whether the model  uses an L2 penalty, the activation function used in the model&#39;s outcome predictors, whether  the data is temporal, the validation metric used for cross validation to find the best  number of neurons, the number of neurons used in the ELMs used by the estimator, the number  of neurons used in the ELM used to learn a mapping from number of neurons to validation  loss during cross validation, the causal effect, standard error, and p-value.</p><pre><code class="language-julia hljs">summarize(g_computer)</code></pre><h2 id="Step-4:-Validate-the-Model"><a class="docs-heading-anchor" href="#Step-4:-Validate-the-Model">Step 4: Validate the Model</a><a id="Step-4:-Validate-the-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Validate-the-Model" title="Permalink"></a></h2><p>We can validate the model by examining the plausibility that the main assumptions of causal  inference, counterfactual consistency, exchangeability, and positivity, hold. It should be  noted that consistency and exchangeability are not directly testable, so instead, these  tests do not provide definitive evidence of a violation of these assumptions. To probe the  counterfactual consistency assumption, we assume there were multiple levels of treatments  and find them by binning the dependent vairable for treated observations using Jenks breaks.  The optimal number of breaks between 2 and num_treatments is found using the elbow method.  Using these hypothesized treatment assignemnts, this method compares the MSE of linear  regressions using the observed and hypothesized treatments. If the counterfactual  consistency assumption holds then the difference between the MSE with hypothesized  treatments and the observed treatments should be positive because the hypothesized  treatments should not provide useful information. If it is negative, that indicates there  was more useful information provided by the hypothesized treatments than the observed  treatments or that there is an unobserved confounder. Next, this methods tests the model&#39;s  sensitivity to a violation of the exchangeability assumption by calculating the E-value,  which is the minimum strength of association, on the risk ratio scale, that an unobserved  confounder would need to have with the treatment and outcome variable to fully explain away  the estimated effect. Thus, higher E-values imply the model is more robust to a violation of  the exchangeability assumption. Finally, this method tests the positivity assumption by  estimating propensity scores. Rows in the matrix are levels of covariates that have a zero  probability of treatment. If the matrix is empty, none of the observations have an estimated  zero probability of treatment, which implies the positivity assumption is satisfied.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>One can also specify the maxium number of possible treatments to consider for the causal  consistency assumption and the minimum and maximum probabilities of treatment for the  positivity assumption with the num_treatments, min, and max keyword arguments.</p></div></div><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>Obtaining correct estimates is dependent on meeting the assumptions for G-computation.  If the assumptions are not met then any estimates may be biased and lead to incorrect  conclusions.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For a thorough review of casual inference assumptions see:</p><pre><code class="nohighlight hljs">Hernan, Miguel A., and James M. Robins. Causal inference what if. Boca Raton: Taylor and 
Francis, 2024.</code></pre><p>For more information on the E-value test see:</p><pre><code class="nohighlight hljs">VanderWeele, Tyler J., and Peng Ding. &quot;Sensitivity analysis in observational research: 
introducing the E-value.&quot; Annals of internal medicine 167, no. 4 (2017): 268-274.</code></pre></div></div><pre><code class="language-julia hljs">validate(g_computer)</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../its/">« Interrupted Time Series Estimation</a><a class="docs-footer-nextpage" href="../doublemachinelearning/">Double Machine Learning »</a><div class="flexbox-break"></div><p class="footer-message">© 2024 Darren Colby</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Monday 29 April 2024 04:01">Monday 29 April 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
